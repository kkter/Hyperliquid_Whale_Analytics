

## Update

### 2025-06-19 

#### 最初的构想

只是想知道这些巨鲸们到底都买了啥？

虽然 Coinglasses 有巨鲸排行榜，
但我想汇总一下，总结一下，
看看他们共同买了啥？做空的巨鲸多还是做多的巨鲸多？
做一个可视化的页面，
而且是动态可视化的。

#### 开始

构建这个项目的第一步是数据采集。
我选择了Coinglass作为数据源，
因为它提供了清晰的巨鲸持仓排行榜。

最初我尝试使用Requests库，但很快发现页面内容是动态加载的，
因此转向了Selenium。

*思考 1: 为什么不在 Coinglasses 直接爬取全部的信息？*
1. 频繁爬取 Coinglasses，担心被封控；
2. 官方API 数据更准确、及时。
所以只从 Coinglasses 爬取关键的地址。

```
核心建议：采用“混合策略”
我的建议是将爬虫和官方API结合使用。

用爬虫做“发现”：Coinglass 这个网站的价值在于它已经帮你整理好了一个“巨鲸地址列表”。这个列表本身更新不会特别频繁（巨鲸的排名不会每分钟都变）。因此，您可以使用爬虫低频率地（例如，每几小时甚至每天一次）访问这个页面，只为了获取最新的巨鲸地址列表（比如前20或前50名）。
用API做“监控”：拿到这个地址列表后，使用Hyperliquid的官方API，传入这些地址，来高频率地获取这些地址实时的、详细的持仓数据（如仓位、盈亏、杠杆等）。
这样做的好处：

降低被封风险：您只对Coinglass进行低频访问，大大降低了因请求过于频繁而被封禁的风险。
数据更可靠、更实时：官方API提供的数据永远是最准确、最及时的。网站爬虫的数据可能有延迟或错误。
爬虫更稳定：您只需要从爬虫获取地址，即使网站页面其他部分改版，只要地址的HTML结构不变，您的爬虫就不需要修改，维护成本低。
```

原来是只打算爬取地址的，
在第一次通过 Selenium 成功爬取地址以后，
发现爬取到的地址并不是排名前20的地址，
只好在网页里继续分析，连排名一起爬取。

在分析这20个地址是，
发现排名第一的地址 `0x5b5d...c060`，出现了三次，
通过比对 Coinglasses 发现是因为它持有的不同的仓位，
所以至少还需要爬取每个地址持有的仓位（也就是币种），
所以从 Coinglasses 共爬取排名、地址、仓位三个信息点,
形成一个简单的“持仓快照”

*思考 2: 使用 json、csv 还是数据库？*

```
数据存储：JSON vs. CSV vs. 数据库
我的建议：立即开始使用数据库，具体选择SQLite。

为什么不用文件：JSON或CSV文件非常适合一次性的数据导入导出。但对于一个需要持续更新、查询、分析的Web应用来说，它们是灾难。每次更新一个小数据，你可能需要读写整个文件，非常低效且容易出错。
为什么用数据库：数据库是专门为高效、安全地存储和检索结构化数据而设计的。这是Web开发的标准实践。
为什么选择SQLite：
零配置：SQLite是一个轻量级的、基于文件的数据库。它不需要你安装和配置一个单独的数据库服务器（像MySQL或PostgreSQL那样）。它在Python中是内置的，使用起来就像操作一个文件一样简单。
功能强大：别看它小，它支持标准的SQL语言，对于您这个项目来说，性能和功能绰绰有余。
求职加分：在简历上写“使用SQLite（或任何数据库）存储和管理数据”远比“把数据存在JSON文件里”要专业得多。
数据模型建议：你可以设计一个表来存储巨鲸持仓记录。
```

### 2025-06-20

拿到地址以后，将地址存进一个数据表。
通过 Hyperliquid 的官方 API 获取仓位的详细信息。

*思考 3：地址的仓位信息存进已经存在的地址还是新建一个新的数据表？*

听从 Gemini 的建议：使用三个数据表。
